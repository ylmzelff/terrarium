simulation:
  max_iterations: 1
  max_planning_rounds: 1
  max_conversation_steps: 3
  seed: 42
  tags:
    - baseline
  note: "Meeting scheduling baseline configuration"

environment:
  name: MeetingSchedulingEnvironment

  # ========== PRODUCTION MODE TOGGLE ==========
  # use_real_calendars: Use real Outlook/Teams via Microsoft Graph API
  # false = Simulation mode (default, no Azure setup needed)
  # true  = Production mode (requires Azure App Registration + M365 account)
  use_real_calendars: false

  num_days: 5
  slots_per_day: 24
  num_meetings: 1
  availability_rate: 0.4   # fraction of slots randomly marked available (simulation mode)
  intersections: 3          # guaranteed common slots in simulation mode

  # ========== MICROSOFT GRAPH API ==========
  # These settings are used when use_real_calendars: true
  # Credentials are read from here first; env vars (AZURE_CLIENT_ID etc.) are fallbacks.
  # SECURITY: Never commit real secrets to a public repo.
  #           Use .env or a secret manager for production credentials.
  graph_api:
    # Azure App Registration — https://portal.azure.com → App registrations
    client_id: "584bab9e-1e06-4e81-805a-de9131078c57"
    tenant_id: "aaac062a-4a59-4297-8e0e-8fed08bb0f74"

    # Timezone for calendar queries (IANA or Windows tz name)
    timezone: "Turkey Standard Time"

    # Path to persist the MSAL token cache between runs
    token_cache_path: "token_cache.bin"

    # true  → clear cached accounts at startup → always triggers device-code flow
    # false → reuse cached tokens silently (faster for repeated runs)
    fresh_auth: true

    # Map each agent name to the Microsoft account email whose calendar to read
    agent_emails:
      AgentA: "elifnr.yilmz@gmail.com"
      AgentB: "ikinci.kullanici@example.com"   # replace with the second user's email

communication_network:
  topology: complete
  num_agents: 2

llm:
  # LLM backend configuration — adjust to your infrastructure
  provider: together_ai          # together_ai | openai | vllm | huggingface
  model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
  temperature: 0.0
  max_tokens: 4096
  trust_remote_code: true