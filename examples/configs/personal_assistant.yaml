simulation:
  max_iterations: 1
  max_planning_rounds: 3
  max_conversation_steps: 3
  tags:
    - baseline
  note: ""
environment:
  name: PersonalAssistant
  # CoLLAB v2 PersonalAssistant (wardrobe coordination)
  num_agents: 6
  density: 0.3
  rng_seed: 42
  min_outfits_per_agent: 3
  max_outfits_per_agent: 4
llm:
  # Provider: "openai", "anthropic", "gemini", or "vllm"
  provider: "openai"
  openai:
    model: "gpt-4.1-mini-2025-04-14"
    params:
      max_tokens: 1024
      temperature: 0.7
      reasoning_effort: "low"
      verbosity: "low"
  anthropic:
    model: "claude-3-5-sonnet-20241022"
    params:
      max_tokens: 4000
      temperature: 0.7
      top_p: 0.95
  gemini:
    model: "gemini-2.0-flash-lite"
    params:
      max_tokens: 1024
      temperature: 0.6
      top_p: 0.95
  vllm:
    auto_start_server: true
    persistent_server: false  # Keep the vLLM server alive between runs to avoid cold starts
    health_check_path: "/models"
    startup_timeout: 420 # When starting a new server, max time (s) to wait for it to be ready
    params:
      max_tokens: 1024
      temperature: 0.7
    models:
      - checkpoint: "Qwen/Qwen2.5-7B-Instruct"
        host: "127.0.0.1"
        port: 8020
        tensor_parallel_size: 1
        gpu_memory_utilization: 0.9
        max_model_len: 16000
        trust_remote_code: true
        additional_args:
          # Will pick the correct parser per model family (e.g., mistral, qwen, hermes)
          - "--enable-auto-tool-choice"
notes:
- PersonalAssistant baseline configuration (no attacks)
- Environment generates outfit coordination factors between agents
- Agents coordinate via blackboards during planning phase
- Final outfit selection happens during execution phase
- Simulation stops when all constraints satisfied or max iterations reached
- Generate n=30 instances and average results for evaluation
